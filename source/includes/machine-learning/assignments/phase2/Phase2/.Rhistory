adult <- rbind(train, test)
names( adult ) <- c('age', 'workclass', 'fnlwght', 'education', 'education_num',
'marital_status', 'occupation', 'relationship', 'race', 'sex',
'capital_gain', 'capital_loss', 'hours_per_week', 'native_country',
train <- read.csv('Datasets/adult.data.txt', stringsAsFactors = FALSE, header = FALSE)
test  <- read.csv('Datasets/adult.test.txt', stringsAsFactors = FALSE, skip = 1, header = FALSE)
adult <- rbind(train, test)
names( adult ) <- c('age', 'workclass', 'fnlwght', 'education', 'education_num',
'marital_status', 'occupation', 'relationship', 'race', 'sex',
'capital_gain', 'capital_loss', 'hours_per_week', 'native_country',
'income')
summarizeColumns(adult)
str( adult )
summarizeColumns(adult)
str( adult )
summarizeColumns(adult) %>% kable()
summarizeColumns(adult) %>%knitr::kable()
summarizeColumns(adult) %>% knitr::kable( caption =  'Feature Summary before Data Preprocessing')
str(adult)
table(adult$income)
summarizeColumns(adult) %>% knitr::kable( caption =  'Feature Summary before Data Preprocessing')
adult %>% select( capital ) %>% filter ( capital < 99999 ) %>% summary()
adult$capital <- adult$capital_gain - adult$capital_loss
adult$capital_gain <- NULL
adult$capital_loss <- NULL
adult %>% select( capital ) %>% filter ( capital < 99999 ) %>% summary()
adult %>% select( capital ) %>% filter ( capital == 99999 ) %>% summarise(count = n())
adult %>% filter ( capital == 99999 ) %>% select( income, capital) %>% table()
sapply( adult[ sapply(adult, is.character)], table)
table(adult$income)
adult$income <- sub('K.', "K", adult$income)
sapply( adult[ sapply(adult, is.character)], table)
train <- read.csv('Datasets/adult.data.txt', stringsAsFactors = FALSE, header = FALSE)
test  <- read.csv('Datasets/adult.test.txt', stringsAsFactors = FALSE, skip = 1, header = FALSE)
adult <- rbind(train, test)
names( adult ) <- c('age', 'workclass', 'fnlwght', 'education', 'education_num',
'marital_status', 'occupation', 'relationship', 'race', 'sex',
'capital_gain', 'capital_loss', 'hours_per_week', 'native_country',
'income')
str(adult)
summarizeColumns(adult) %>% knitr::kable( caption =  'Feature Summary before Data Preprocessing')
adult[, sapply( adult, is.character )] <- sapply( adult[, sapply( adult, is.character )], trimws)
table(adult$income)
adult$income <- sub('K.', "K", adult$income)
table(adult$income)
adult$income <- sub('K.', "K", adult$income)
adult$capital <- adult$capital_gain - adult$capital_loss
adult$capital_gain <- NULL
adult$capital_loss <- NULL
adult %>% select( capital ) %>% filter ( capital < 99999 ) %>% summary()
adult %>% select( capital ) %>% filter ( capital == 99999 ) %>% summarise(count = n())
adult %>% filter ( capital == 99999 ) %>% select( income, capital) %>% table()
sapply( adult[ sapply(adult, is.character)], table)
adult <- adult %>%
mutate( workclass1 = ifelse( workclass %in% c('?', 'Never-worked', 'Without-pay'), "Other",
ifelse( grepl('gov', workclass), 'gov',
ifelse( grepl('Self-emp', workclass), 'Self-emp', workclass )) ),
education1 = ifelse( grepl('th', education) | education == 'Preschool', 'Before-HS',
ifelse( education %in% c('Doctorate', 'Masters', 'Prof-school'), 'Postgrad',
ifelse( grepl( 'Assoc', education ), 'Assoc', education ) ) ),
native_country1 = ifelse( native_country != 'United-States', 'Not US', 'United-States'),
marital_status1 = ifelse( grepl( 'Married', marital_status ), 'Married', marital_status),
occupation1 = ifelse( occupation == '?', 'Other', occupation)
)
adult <- adult %>%
mutate( workclass1 = ifelse( workclass %in% c('?', 'Never-worked', 'Without-pay'), "Other",
ifelse( grepl('gov', workclass), 'gov',
ifelse( grepl('Self-emp', workclass), 'Self-emp', workclass )) ),
education1 = ifelse( grepl('th', education) | education == 'Preschool', 'Before-HS',
ifelse( education %in% c('Doctorate', 'Masters', 'Prof-school'), 'Postgrad',
ifelse( grepl( 'Assoc', education ), 'Assoc', education ) ) ),
native_country1 = ifelse( native_country != 'United-States', 'Not US', 'United-States'),
marital_status1 = ifelse( grepl( 'Married', marital_status ), 'Married', marital_status),
occupation1 = ifelse( occupation == '?', 'Other', occupation)
)
adult[, sapply( adult, is.character )] <- lapply( adult[, sapply( adult, is.character )], factor)
adult$fnlwght <- NULL
summarizeColumns(adult) %>% knitr::kable( caption = 'Feature Summary before Data Preprocessing' )
ggplot(adult, aes(x = age)) + geom_histogram(bins = 35)
ggplot(adult, aes(x = age, fill = income)) +
geom_histogram(bins = 35) + facet_grid(~income)
ggplot(adult, aes(x = hours_per_week)) + geom_histogram(bins = 20)
ggplot(adult, aes(x = hours_per_week, fill = income)) +
geom_histogram(bins = 20) + facet_grid(~income)
# 1. Packages  ----
library(mlr)
library(tidyverse)
library(GGally)
# 2. Data Processing ----
# 2.1. Preliminaries ----
train <- read.csv('datasets/adult.data.txt', stringsAsFactors = FALSE, header = FALSE)
test  <- read.csv('datasets/adult.test.txt', stringsAsFactors = FALSE, skip = 1, header = FALSE)
source('phase1_dataProcessing.R')
exists('adult')
!exists('adult')
if( !exists('adult')  ){
stop('No Adult Data')
}else{
# 3. Visualisation ----
# 3.1 Univariate Visualisation ---
# 3.1.1 Numerical Features ----
ggplot(adult, aes(x = age)) + geom_histogram(bins = 35)
ggplot(adult, aes(x = age, fill = income)) + geom_histogram(bins = 35) + facet_grid(~income)
ggplot(adult, aes(x = hours_per_week)) + geom_histogram(bins = 20)
ggplot(adult, aes(x = hours_per_week, fill = income)) + geom_histogram(bins = 20) + facet_grid(~income)
ggplot(adult, aes(x = education_num)) + geom_bar()
ggplot(adult, aes(x = education_num, fill = income)) + geom_bar() + facet_grid(~income)
ggplot(adult, aes(x = capital)) + geom_histogram(bins = 20)
ggplot(adult, aes(x = capital, fill = income)) + geom_bar() + facet_grid(~income)
ggplot(adult %>% mutate(capital = ifelse( capital > 0 , 'gain', 'loss') ),
aes(x = capital, fill = income)) + geom_bar() + facet_grid(~income)
# 3.1.2 Categorical Features ----
ggplot(adult, aes(x = workclass)) + geom_bar()
ggplot(adult, aes(x = workclass, fill = income)) + geom_bar() + facet_grid(income~.)
ggplot(adult, aes(x = education)) + geom_bar()
ggplot(adult, aes(x = education, fill = income)) + geom_bar() + facet_grid(income~.)
ggplot(adult, aes(x = marital_status)) + geom_bar()
ggplot(adult, aes(x = marital_status, fill = income)) + geom_bar() + facet_grid(income~.)
ggplot(adult, aes(x = occupation)) + geom_bar()
ggplot(adult, aes(x = occupation, fill = income)) + geom_bar() + facet_grid(income~.)
ggplot(adult, aes(x = relationship)) + geom_bar()
ggplot(adult, aes(x = relationship, fill = income)) + geom_bar() + facet_grid(income~.)
ggplot(adult, aes(x = race)) + geom_bar()
ggplot(adult, aes(x = race, fill = income)) + geom_bar() + facet_grid(income~.)
ggplot(adult, aes(x = native_country )) + geom_bar()
ggplot(adult, aes(x = native_country , fill = income)) + geom_bar() + facet_grid(income~.)
# 3.2 Multvariate Visualisation ----
# 3.2.1. Scatterplot Matrix ----
# ggpairs( adult,  aes(color = income))
# 3.2.2 Others ----
}
citation('knitr')
options(citation.bibtex.max=999)
citation('knitr')
ggplot(adult, aes(x = capital)) + geom_histogram(bins = 20)
ggplot(adult, aes(x = capital)) + geom_histogram(bins = 20)
?scale
adult
adult %>% mutate( capital = scale(capital))
library(tidyverse)
adult %>% mutate( capital = scale(capital))
adult %>% mutate( capital = scale(capital)) %>% ggplot( aes(x = capital\))
adult %>% mutate( capital = scale(capital)) %>% ggplot( aes(x = capital))
adult %>% mutate( capital = c(scale(capital))) %>% ggplot( aes(x = capital))
ggplot(adult, aes(x = age, fill = income)) + geom_histogram() +
facet_grid(sex~education1)
install.packages("GGally")
install.packages("cowplot")
adult$education_num <- NULL
write.csv(adult, 'cleaned_adult.csv', row.names = FALSE)
rm(list = ls())
# 1. Preliminaries ----
library(mlr)
# 1. Preliminaries ----
library(mlr)
library(tidyverse)
data <- read.csv('cleaned_adult.csv')
# 2. Modeling ----
learner1 <- makeLearner('classif.randomForest')
str(data)
data <- data %>% select(-workclass, -education, -marital_status, -native_country)
str(data)
rm(list = ls())
data <- read.csv('cleaned_adult.csv')
data <- data %>%
select(-workclass, -education, -marital_status, -native_country, -occupation)
str(data)
# 2. Modeling ----
# Configure classification task
task <- makeClassifTask(data = data, id = 'income')
rm(list = ls())
data <- read.csv('cleaned_adult.csv')
# Remove the granular features
data <- data %>%
select(-workclass, -education, -marital_status, -native_country, -occupation)
str(data)
# 2. Modeling ----
# Configure classification task
task <- makeClassifTask(data = data, id = 'income')
# Configure learners
learner1 <- makeLearner('classif.naiveBayes')
learner2 <- makeLearner('classif.randomForest')
learner3 <- makeLearner('classif.kknn')
# 2.2 Model training ----
getParamSet(learner1)
# 2.2 Model training ----
# Obtain parameters available for fine-tuning
getParamSet(learner1)
getParamSet(learner2)
getParamSet(learner3)
# For naiveBayes, we can fine-tune Laplacian
# For randomForest, we can fine-tune mtry
library(randomForest)
?randomForest
11^0.5
getParamSet(learner3)
# For naiveBayes, we can fine-tune Laplacian
# For randomForest, we can fine-tune mtry i.e mumber of variables randomly
# sampled as candidates at each split. Following
# Breiman, L. (2001), Random Forests, Machine Learning 45(1), 5-32,
# we can try mtry = 2, 3, 4 as mtry = sqrt(p) where p = 11
?kknn
table(data$income)
# Spliting the data into 60 % training, 30 % validation, and 10 % test data
getTaskSize(task)
# 2. Modeling ----
# 2.1. Basic configuration ----
# Configure classification task
task <- makeClassifTask(data = data, target = 'income', id = 'adult')
# Spliting the data into 60 % training, 30 % validation, and 10 % test data
getTaskSize(task)
# Spliting the data into 70 % training & 30 % test data
nrow(data)*0.70
# Spliting the data into 70 % training & 30 % test data
sample(nrow(data)*0.70)
?sample
# Spliting the data into 70 % training & 30 % test data
training_index <- sample(nrow(data)*0.70)
test_index     <- seq(1:nrow(data))
?trainControl
# Spliting the data into 70 % training & 30 % test data
library(splitstackshape)
set.seed(1)
out <- stratified(d, c("age", "lc"), 30)
out <- stratified(data, c("income"), 30)
head(out)
out <- stratified(data, c("income"), nrow(data)*0.3)
out <- stratified(data, c("income"), floor(nrow(data)*0.3))
out <- stratified(data, c("income"), floor(nrow(data)*0.2))
head(out)
table(out$income)
# Spliting the data into 70 % training & 30 % test data
training_index <- sample(nrow(data)*0.70)
test_index     <- diff(seq(1:nrow(data)), training_index )
test_index     <- setdiff(seq(1:nrow(data)), training_index )
# 1. Preliminaries ----
library(mlr)
library(tidyverse)
rm(list = ls())
data <- read.csv('cleaned_adult.csv')
# Remove the granular features
data <- data %>%
select(-workclass, -education, -marital_status, -native_country, -occupation)
str(data)
table(data$income)
# Set a common random seed for reproducibility
set.seed(1234)
# Old school way to spliting the data into 70 % training & 30 % test data
# This is not stratified sampling, which shall be used in model training
# obtain index for training and test indices
training_index <- sample(nrow(data)*0.70)
test_index     <- setdiff(seq(1:nrow(data)), training_index )
# Get the training data and test data
# Get the training data and test data
training_data  <- data[training_index, ]
test_data      <- data[test_index, ]
# Check the proportion of income in each dataset
prop.table(table(training_data$income))
prop.table(table(test_data$income))
# 2. Modeling ----
# 2.1. Basic configuration ----
# Configure classification task
task <- makeClassifTask(data = training_data, target = 'income', id = 'adult')
# Configure learners with probability type
learner1 <- makeLearner('classif.naiveBayes', predict.type = 'prob')    # baseline learner
learner2 <- makeLearner('classif.randomForest', predict.type = 'prob')
learner3 <- makeLearner('classif.kknn', predict.type = 'prob')
# 2.2 Model fine-tuning ----
# Obtain parameters available for fine-tuning
getParamSet(learner1)
getParamSet(learner2)
getParamSet(learner3)
# For randomForest, we can fine-tune mtry i.e mumber of variables randomly
# For randomForest, we can fine-tune mtry i.e mumber of variables randomly
# sampled as candidates at each split. Following
# For randomForest, we can fine-tune mtry i.e mumber of variables randomly
# sampled as candidates at each split. Following
# Breiman, L. (2001), Random Forests, Machine Learning 45(1), 5-32,
# For randomForest, we can fine-tune mtry i.e mumber of variables randomly
# sampled as candidates at each split. Following
# Breiman, L. (2001), Random Forests, Machine Learning 45(1), 5-32,
# we can try mtry = 2, 3, 4 as mtry = sqrt(p) where p = 11
# For randomForest, we can fine-tune mtry i.e mumber of variables randomly
# sampled as candidates at each split. Following
# Breiman, L. (2001), Random Forests, Machine Learning 45(1), 5-32,
# we can try mtry = 2, 3, 4 as mtry = sqrt(p) where p = 11
#
# For randomForest, we can fine-tune mtry i.e mumber of variables randomly
# sampled as candidates at each split. Following
# Breiman, L. (2001), Random Forests, Machine Learning 45(1), 5-32,
# we can try mtry = 2, 3, 4 as mtry = sqrt(p) where p = 11
#
# For kknn, we can fine-tune k = 2 to 20 and
11^0.5
# For kknn, we can fine-tune k = 2 to 20 and
# two kernels = {rectangular, triangular}
ps3 <- makeParamSet(
makeDiscreteParam('k', values = seq(2, 20, by = 1)),
?makeDiscreteParam
)
?makeDiscreteParam
getParamSet(learner3)
# 1. Preliminaries ----
library(mlr)
library(tidyverse)
rm(list = ls())
data <- read.csv('cleaned_adult.csv')
# Remove the granular features
data <- data %>%
select(-workclass, -education, -marital_status, -native_country, -occupation)
str(data)
table(data$income)
# Set a common random seed for reproducibility
set.seed(1234)
# Old school way to spliting the data into 70 % training & 30 % test data
# This is not stratified sampling, which shall be used in model training
# obtain index for training and test indices
training_index <- sample(nrow(data)*0.70)
test_index     <- setdiff(seq(1:nrow(data)), training_index )
# Get the training data and test data
training_data  <- data[training_index, ]
test_data      <- data[test_index, ]
# Check the proportion of income in each dataset
prop.table(table(training_data$income))
prop.table(table(test_data$income))
# They are quite balanced and representative of the full dataset
# We shall use training data for modeling
# and test data for model evaluation
# 2. Modeling ----
# 2.1. Basic configuration ----
# Configure classification task
task <- makeClassifTask(data = training_data, target = 'income', id = 'adult')
# Configure learners with probability type
learner1 <- makeLearner('classif.naiveBayes', predict.type = 'prob')    # baseline learner
learner2 <- makeLearner('classif.randomForest', predict.type = 'prob')
learner3 <- makeLearner('classif.kknn', predict.type = 'prob')
# 2.2 Model fine-tuning ----
# Obtain parameters available for fine-tuning
getParamSet(learner1)
getParamSet(learner2)
getParamSet(learner3)
# For naiveBayes, we can fine-tune Laplacian
ps1 <- makeParamSet(
makeNumericParam('laplace', lower = 0, upper = 30)
)
# For randomForest, we can fine-tune mtry i.e mumber of variables randomly
# sampled as candidates at each split. Following
# Breiman, L. (2001), Random Forests, Machine Learning 45(1), 5-32,
# we can try mtry = 2, 3, 4 as mtry = sqrt(p) where p = 11
ps2 <- makeParamSet(
makeDiscreteParam('mtry', values = c(2,3,4))
)
# For kknn, we can fine-tune k = 2 to 20
ps3 <- makeParamSet(
makeDiscreteParam('k', values = seq(2, 20, by = 1))
)
tunedLearner1 <- makeTuneWrapper(learner1, rdesc, mmce, ps1, ctrl)
# Configure tune control search and a 5-CV stratified sampling
ctrl  <- makeTuneControlGrid()
rdesc <- makeResampleDesc("CV", iters = 5L, stratify = TRUE)
tunedLearner1 <- makeTuneWrapper(learner1, rdesc, mmce, ps1, ctrl)
# 1. Preliminaries ----
library(mlr)
library(tidyverse)
rm(list = ls())
data <- read.csv('cleaned_adult.csv')
# Remove the granular features
data <- data %>%
select(-workclass, -education, -marital_status, -native_country, -occupation)
str(data)
table(data$income)
# Set a common random seed for reproducibility
set.seed(1234)
# Old school way to spliting the data into 70 % training & 30 % test data
# This is not stratified sampling, which shall be used in model training
# obtain index for training and test indices
training_index <- sample(nrow(data)*0.70)
test_index     <- setdiff(seq(1:nrow(data)), training_index )
# Get the training data and test data
training_data  <- data[training_index, ]
test_data      <- data[test_index, ]
# Check the proportion of income in each dataset
prop.table(table(training_data$income))
prop.table(table(test_data$income))
# They are quite balanced and representative of the full dataset
# We shall use training data for modeling
# and test data for model evaluation
# 2. Modeling ----
# 2.1. Basic configuration ----
# Configure classification task
task <- makeClassifTask(data = training_data, target = 'income', id = 'adult')
# Configure learners with probability type
learner1 <- makeLearner('classif.naiveBayes', predict.type = 'prob')    # baseline learner
learner2 <- makeLearner('classif.randomForest', predict.type = 'prob')
learner3 <- makeLearner('classif.kknn', predict.type = 'prob')
# 2.2 Model fine-tuning ----
# Obtain parameters available for fine-tuning
getParamSet(learner1)
getParamSet(learner2)
getParamSet(learner3)
# For naiveBayes, we can fine-tune Laplacian
ps1 <- makeParamSet(
makeNumericParam('laplace', lower = 0, upper = 30)
)
# For randomForest, we can fine-tune mtry i.e mumber of variables randomly
# sampled as candidates at each split. Following
# Breiman, L. (2001), Random Forests, Machine Learning 45(1), 5-32,
# we can try mtry = 2, 3, 4 as mtry = sqrt(p) where p = 11
ps2 <- makeParamSet(
makeDiscreteParam('mtry', values = c(2,3,4))
)
# For kknn, we can fine-tune k = 2 to 20
ps3 <- makeParamSet(
makeDiscreteParam('k', values = seq(2, 20, by = 1))
)
# Configure tune control search and a 5-CV stratified sampling
ctrl  <- makeTuneControlGrid()
rdesc <- makeResampleDesc("CV", iters = 5L, stratify = TRUE)
# Configure tune wrapper with tune-tuning settings
tunedLearner1 <- makeTuneWrapper(learner1, rdesc, mmce, ps1, ctrl)
tunedLearner2 <- makeTuneWrapper(learner2, rdesc, mmce, ps2, ctrl)
tunedLearner3 <- makeTuneWrapper(learner3, rdesc, mmce, ps3, ctrl)
# Train the tune wrappers
tunedMod1  <- train(tunedLearner1, task)
tunedMod2  <- train(tunedLearner2, task)
tunedMod3  <- train(tunedLearner3, task)
# Predict on training data
tunedPred1 <- predict(tunedMod1, task)
tunedPred2 <- predict(tunedMod2, task)
# Predict on training data
tunedPred1 <- predict(tunedMod1, task)
tunedPred2 <- predict(tunedMod2, task)
tunedPred3 <- predict(tunedMod3, task)
tunedPred3 <- predict(tunedMod3, task)
# Obtain threshold values
d1 <- generateThreshVsPerfData(tunedPred1, measures = list(mmce, auc))
plotThreshVsPerf(d1)
d2 <- generateThreshVsPerfData(tunedPred2, measures = list(mmce, auc))
d3 <- generateThreshVsPerfData(tunedPred3, measures = list(mmce, auc))
plotThreshVsPerf(d1)
plotThreshVsPerf(d2)
plotThreshVsPerf(d3)
plotThreshVsPerf(d1)
plotThreshVsPerf(d2)
plotThreshVsPerf(d3)
d1$measures
d1$data
# Obtain threshold values for each learner
d1 <- generateThreshVsPerfData(tunedPred1, measures = list(mmce))
d2 <- generateThreshVsPerfData(tunedPred2, measures = list(mmce))
d3 <- generateThreshVsPerfData(tunedPred3, measures = list(mmce))
plotThreshVsPerf(d1)
plotThreshVsPerf(d2)
plotThreshVsPerf(d3)
d1$data
which.min(d1$data$mmce)
d1$data$threshold[which.min(d1$data$mmce)]
d2$data$threshold[ which.min(d2$data$mmce) ]
d3$data$threshold[ which.min(d3$data$mmce) ]
# 3. Evaluation on test data ----
# we shall use tuned wrapper models and optimal thresholds from previous sections
testPred1 <- predict(tunedMod1, newdata = test_data)
testPred2 <- predict(tunedMod2, newdata = test_data)
testPred3 <- predict(tunedMod3, newdata = test_data)
testPred3 <- predict(tunedMod3, newdata = test_data)
testPred1 <- setThreshold(testPred1, threshold1 )
# Get threshold for each learner
threshold1 <- d1$data$threshold[ which.min(d1$data$mmce) ]
threshold2 <- d2$data$threshold[ which.min(d2$data$mmce) ]
threshold3 <- d3$data$threshold[ which.min(d3$data$mmce) ]
testPred1 <- setThreshold(testPred1, threshold1 )
testPred1 <- setThreshold(testPred1, threshold1 )
testPred2 <- setThreshold(testPred2, threshold2 )
testPred3 <- setThreshold(testPred3, threshold3 )
calculateConfusionMatrix( testPred1  )
performance( testPred1 )
performance( testPred2 )
calculateConfusionMatrix( testPred2  )
performance( testPred2 )
?calculateConfusionMatrix
calculateConfusionMatrix( testPred1,relative = TRUE)
calculateConfusionMatrix( testPred2,relative = TRUE)
calculateConfusionMatrix( testPred3,relative = TRUE)
performance( testPred3 )
plotThreshVsPerf(d1)
plotThreshVsPerf(d1) + labs(title = 'Threshold Adjustment for Naive Bayes', x = 'Threshold')
plotThreshVsPerf(d2) + labs(title = 'Threshold Adjustment for Random Forest', x = 'Threshold')
plotThreshVsPerf(d3) + labs(title = 'Threshold Adjustment for KNN', x = 'Threshold')
11^0.5
# Get threshold for each learner
threshold1 <- d1$data$threshold[ which.min(d1$data$mmce) ]
threshold2 <- d2$data$threshold[ which.min(d2$data$mmce) ]
threshold3 <- d3$data$threshold[ which.min(d3$data$mmce) ]
# 3. Evaluation on test data ----
# we shall use tuned wrapper models and optimal thresholds from previous sections
testPred1 <- predict(tunedMod1, newdata = test_data)
testPred2 <- predict(tunedMod2, newdata = test_data)
testPred3 <- predict(tunedMod3, newdata = test_data)
testPred1 <- setThreshold(testPred1, threshold1 )
testPred2 <- setThreshold(testPred2, threshold2 )
testPred3 <- setThreshold(testPred3, threshold3 )
```{r, echo = FALSE}
calculateConfusionMatrix( testPred1,relative = TRUE)
calculateConfusionMatrix( testPred2,relative = TRUE)
calculateConfusionMatrix( testPred3,relative = TRUE)
performance( testPred1 )
performance( testPred2 )
performance( testPred3 )
?makeFilterWrapper(
)
# Get threshold for each learner
threshold1 <- d1$data$threshold[ which.min(d1$data$mmce) ]
