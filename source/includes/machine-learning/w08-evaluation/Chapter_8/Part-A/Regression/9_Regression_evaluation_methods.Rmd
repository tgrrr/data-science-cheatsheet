---
title: 'Machine Learning: Chapter 8 - Part I'
subtitle: 'Evaluation Methods for Regression Problems'
version: 1
author:
date:
output: 
  pdf_document:
    fig_caption: true
    toc_depth: 4
    number_sections: true
referencecolor: blue
linkcolor: blue
link-citations: yes
references:
- id: kelleher
  type: book
  issued:
    - year: 2015
  author:
  - family: Kelleher
    given: John D.
  - family: Namee
    given: Brian Mac
  - family: D'Arcy
    given: Aoife
  publisher: The MIT Press
  title: "Fundamentals of Machine Learning for Predictive Data Analytics"
  subtitle: "Algorithms, Worked Examples, and Case Studies"
- id: hadley
  title: "tidyverse: Easily Install and Load Tidyverse Packages"
  author: 
  - given: Hadley 
    family: Wickham
  issued:
    year: 2016
  url: https://CRAN.R-project.org/package=tidyverse
- id: hadley2
  title: "dplyr: A Grammar of Data Manipulation"
  author: 
  - given: Hadley 
    family: Wickham
  - given: Francois
    family: Romain
  - given: Henry
    family: Lionel
  - given: MÃ¼ller
    family: Kirill
  issued:
    year: 2017
  url: https://CRAN.R-project.org/package=dplyr
- id: yihui
  author:
  - family: Xie
    given: Yihui
  type: article-journal
  title: "knitr: A General-Purpose Package for Dynamic Report Generation in R"
  issued:
    year: 2016
- id: mlr
  title: "`mlr`: Machine Learning in R"
  author:
  - family: Bischl
    given: Bernd
  - family: Lang
    given: Michel
  - family: Kotthoff
    given: Lars
  - family: Schiffner
    given: Julia
  - family: Richter
    given: Jakob
  - family: Studerus
    given: Erich
  - family: Casalicchio
    given: Giuseppe 
  - family: Jones
    given: Zachary M.
  url: http://jmlr.org/papers/v17/15-066.html
  issued:
  - year: 2016
  volume: 17
  pages: 1-5
  publisher: Journal of Machine Learning Research
- id: ron
  author:
  - family: Kohavi
    given: Ron
  type: article-journal
  title: "Scaling Up the Accuracy of Naive-Bayes Classifiers: a Decision-Tree Hybrid"
  issued:
    year: 1996
  publisher: Proceedings of the Second International Conference on Knowledge Discovery and Data Mining

---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, comment = NA)
```

# Overview

Compared to classification problems, there are fewer measures to evaluate model performance for a regression problem. There shall be no confusion matrix and threshold adjustment. In this document, we shall use Boston Housing dataset to illustrate how to obtain mainly used evaluation measures. Boston Housing dataset can be called via `MASS` package:

```{r, message=FALSE, warning=FALSE}
library(MASS)
data("Boston")

```

# Preliminaries

Using 13 descriptive features, the goal is to predict `medv`, the median value of owner-occupied homes in US dollars. Let's configure a regression task and two learners: linear regression and KNN for comparison. For each learner, we train a model.

```{r, message=FALSE, warning=FALSE}
library(mlr)
regrTask  <- makeRegrTask(data = Boston, target = 'medv')
learner1  <- makeLearner('regr.lm')    # linear regression
learner2  <- makeLearner('regr.kknn')  # kknn

# Train model for each learner
mod1  <- train(learner1, regrTask) # linear regression model
mod2  <- train(learner2, regrTask) # knn model
```

# Evaluation Methods

Before we proceed to evaluate the models, we need to decide which measure to use. To find out which performance measures are available for a regression task, we can call `listMeasures`.

```{r}
listMeasures(regrTask)

```

`listMeasures(regrTask)` returns many measures. Some are interpretable, for example, we can guess that `rsq` means R-squared and `mse` means mean squared error. How about `kendalltau` and `expvar`? To find out their **properties**, say more details about `rsq`, we can use `str` function:

```{r}
str(rsq)

```

The key properties are:

1. `minimize`: where a lower value is better. For `rsq`, it is `FALSE`. Therefore, we aim a higher value from a better model
2. `best`: the best value to represent the best performance. For `rsq`, it is 1
3. `worst`: the worst value to represent the worst performance, For `rsq`, it is `-Inf`, although it should be 0 as explained by @kelleher[, Section 8.4.5.2].
4. `name`: the name of measure. The "statistical name" of `rsq` is "coeffiecient of determination"
5. `note`: extra description of measure. It gives the definition of `rsq` which is the same as Equation 8.29 on the textbook [@kelleher].


Let's predict on full data set and evaluate the performance on each model using `task` as follow:

```{r}
pred1 <- predict(mod1, regrTask)   # linear regression model
pred2 <- predict(mod2, regrTask)   # knn model

```

\color{blue}A side note\color{black}: we can also make predictions via `predict(mod1, newdata = BostonHousing)`. Make sure to include `newdata` in the `predict`. The default performance of a regression problem is `mse` (mean squared error). 

```{r}
performance(pred1)
performance(pred2)
```

To include other measures, we can wrap them in a list below, say `sse`, `mse`, `rsq`, `mae` and `rmse`. 

```{r}
performance(pred1, measures = list(sse, mse, rmse, rsq, mae))
performance(pred2, measures = list(sse, mse, rmse, rsq, mae))

```


\color{red}**Questions** \color{black}

1. What are `sse`, `mse`, `mae` and `rmse`? Hint: use `str`.
2. Based on these measures, which learner has a better performance?
3. Among these measures above, which of them has the same unit of target feature (i.e. `medv`)?
4. Compared to `rmse`, what is the advantage of `mae`?
5. Which measure is domain-independent? When do we need domain-independent measures?

\color{blue}Hint\color{black}: See @kelleher[, Section 8.4.5].

# Caution

`mlr` will throw error messages that we have assigned an object with the same name of one of the measures. For example, say we have created an object named `sse` and assigned it with some value:

```{r}
sse <- 1233
```

Because `R` will search for an object named `sse` in the global environment (a place where you store data and objects you create), it will no longer treat it as a measure object. Therefore, when you run the following, `R` will result in error!

```{r, eval = FALSE}
performance(pred1, measures = list(sse))
```

To solve it, we should remove `sse` using `rm` function

```{r}
rm(sse)
performance(pred1, measures = list(sse))
```

# Reference